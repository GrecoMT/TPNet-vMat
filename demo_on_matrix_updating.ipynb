{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd7cee5-4a64-49ad-80b0-10480e2209e2",
   "metadata": {},
   "source": [
    "### A Demo About Temporal Walk Matrix Maintaining\n",
    "In this demo, we will show how to explictly and implicitly maintain different temporal walk matrices at single interaction level and batch interaction level. \n",
    "\n",
    "The element of a k-hop temporal walk matrix is.\n",
    "$$\n",
    "A_{u,v}^{(k)}(t) = \\sum_{W\\in M_{u,v}^{k}(t)} s(W),\n",
    "$$\n",
    "where $M_{u,v}^k(t)$ is the set of all k-step temporal walks from u to v, and $s(\\cdot)$ is the score function.\n",
    "\n",
    "Denoting a temporal walk as $W=[(w_0,t_0),(w_1,t_1),...,(w_k,t_k)]$ and current time as $t$, we consider the following two types of temporal walk matrices.\n",
    "- Sum Matirx: its score function is $s(W)=\\prod_{i=0}^{k} \\text{exp}(-\\lambda(t-t_i))$.\n",
    "- Norm Matrix: its score function is $s(W)=\\prod_{i=0}^{k-1} \\frac{\\text{exp}(-\\lambda(t_{i}-t_{i+1}))}{\\sum_{(\\{w',w\\},t')\\in \\mathcal{E}_{w_i,t_i}} \\text{exp}(-\\lambda(t_i-t'))}$.\n",
    "\n",
    "The sum matrix corresponds to the matrix of TPNet and the norm matrix correspond to the matrix of CAWN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878ca77-1123-4c01-9419-834b78516e0c",
   "metadata": {},
   "source": [
    "#### Basic Utils\n",
    "Basic utils including a function to genearte random temporal graphs and a function to compute the temporal walk matrices by brute force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4d7e47-5965-46d6-b0c2-45f8c9b0cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "\n",
    "def generate_graph(node_num, edge_num):\n",
    "    node_list = [i for i in range(node_num)]\n",
    "    previous_time = 0\n",
    "    src_node_ids = []\n",
    "    dst_node_ids = []\n",
    "    node_interact_times = []\n",
    "    for i in range(edge_num):\n",
    "        u = np.random.choice(node_list)\n",
    "        v = np.random.choice(node_list[:u] + node_list[u + 1:])\n",
    "        t = previous_time + np.random.randint(1, 5)\n",
    "        src_node_ids.append(u)\n",
    "        dst_node_ids.append(v)\n",
    "        node_interact_times.append(t)\n",
    "        previous_time = t\n",
    "    return np.array(src_node_ids), np.array(dst_node_ids), np.array(node_interact_times)\n",
    "\n",
    "def get_matrix_by_brute_force(src_node_ids, dst_node_ids, interact_times, matrix_type,num_layer,lam,node_num):\n",
    "    \"\"\"\n",
    "    given a temporal graph G(t), generate the temporal walk matrices at t+1 by brute force.\n",
    "    \"\"\"\n",
    "    adj_node = [[] for i in range(node_num)]\n",
    "    adj_time = [[] for i in range(node_num)]\n",
    "    for i in range(len(src_node_ids)):\n",
    "        u, v, t = src_node_ids[i], dst_node_ids[i], interact_times[i]\n",
    "        adj_node[u].append(v)\n",
    "        adj_time[u].append(t)\n",
    "        adj_node[v].append(u)\n",
    "        adj_time[v].append(t)\n",
    "\n",
    "    matrices = [torch.zeros((node_num, node_num)) for i in range(num_layer + 1)]\n",
    "    last_time = interact_times[-1] + 1\n",
    "\n",
    "    def dfs(now_node, now_time, node_list, time_list, score_list):\n",
    "        pos = np.searchsorted(adj_time[now_node], now_time, 'left')\n",
    "        if pos > 0 and len(node_list) <= num_layer:\n",
    "            normalize_weight = np.sum(np.exp(-lam * (now_time - np.array(adj_time[now_node][:pos]))))\n",
    "            for i in range(pos):\n",
    "                next_node, next_time = adj_node[now_node][i], adj_time[now_node][i]\n",
    "                if matrix_type == 'norm':\n",
    "                    weight = np.exp(-lam * (now_time - next_time)) / normalize_weight\n",
    "                elif matrix_type == 'sum':\n",
    "                    weight = np.exp(-lam * (last_time - next_time))\n",
    "                else:\n",
    "                    raise ValueError(\"Not Implemented Matrix Type\")\n",
    "                dfs(next_node, next_time, node_list + [next_node], time_list + [next_time], score_list + [weight])\n",
    "\n",
    "        u, v, hop = node_list[0], node_list[-1], len(node_list) - 1\n",
    "        matrices[hop][u, v] += reduce(lambda a, b: a * b, score_list)\n",
    "\n",
    "    for i in range(node_num):\n",
    "        dfs(i, last_time, [i], [last_time], [1])\n",
    "\n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe69dd-bfcc-4206-8806-3cbb2f7ede7f",
   "metadata": {},
   "source": [
    "#### Matrix Updating Function for Single Interaction Updating\n",
    "Given a temporal graph $G(t)$, if different interactions have different timestamps, the following two functions compute the corresponding temporal walk matrices at $t+1$ by updating the matrices incrementally, one interaction at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04192eef-7c7d-4da4-9e44-e0745c755620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_matrix(src_node_ids, dst_node_ids, interact_times, num_layer, node_num, lam, use_projection, dimension):\n",
    "    \"\"\"\n",
    "    given a temporal graph G(t), generate the norm temporal walk matrices at t+1.\n",
    "    \"\"\"\n",
    "    if use_projection:\n",
    "        matrices = [torch.normal(0, 1 / math.sqrt(dimension), (node_num, dimension))]\n",
    "        matrices = matrices + [torch.zeros(node_num, dimension) for i in range(num_layer)]\n",
    "    else:\n",
    "        matrices = [torch.eye(node_num)] + [torch.zeros((node_num, node_num)) for i in range(num_layer)]\n",
    "\n",
    "    degree = torch.zeros(node_num)\n",
    "    previous_time = 0\n",
    "    for i in range(len(src_node_ids)):\n",
    "        u, v, t = src_node_ids[i], dst_node_ids[i], interact_times[i]\n",
    "        # move current timestamp to t\n",
    "        degree = degree * np.exp(-lam * (t - previous_time))\n",
    "        # add interaction\n",
    "        for j in range(num_layer, 0, -1):\n",
    "            matrices[j][u] = (matrices[j][u] * degree[u] + matrices[j - 1][v]) / (degree[u] + 1)\n",
    "            matrices[j][v] = (matrices[j][v] * degree[v] + matrices[j - 1][u]) / (degree[v] + 1)\n",
    "        degree[u] = degree[u] + 1\n",
    "        degree[v] = degree[v] + 1\n",
    "        previous_time = t\n",
    "    \n",
    "    # esitmate the matrix by inner product\n",
    "    if use_projection:\n",
    "        matrices = [matrices[i] @ matrices[0].T for i in range(num_layer + 1)]\n",
    "    return matrices\n",
    "\n",
    "def get_sum_matrix(src_node_ids, dst_node_ids, interact_times, num_layer, node_num, lam, use_projection, dimension):\n",
    "    \"\"\"\n",
    "    given a temporal graph G(t), generate the sum temporal walk matrices at t+1.\n",
    "    \"\"\"\n",
    "    if use_projection:\n",
    "        matrices = [torch.normal(0, 1 / math.sqrt(dimension), (node_num, dimension))]\n",
    "        matrices = matrices + [torch.zeros(node_num, dimension) for i in range(num_layer)]\n",
    "    else:\n",
    "        matrices = [torch.eye(node_num)] + [torch.zeros((node_num, node_num)) for i in range(num_layer)]\n",
    "\n",
    "    previous_time = 0\n",
    "    for i in range(len(src_node_ids)):\n",
    "        u, v, t = src_node_ids[i], dst_node_ids[i], interact_times[i]\n",
    "        for j in range(num_layer, 0, -1):\n",
    "            matrices[j] = matrices[j] * np.power(np.exp(-lam * (t - previous_time)), j)\n",
    "        for j in range(num_layer, 0, -1):\n",
    "            matrices[j][u] = matrices[j][u] + matrices[j - 1][v]\n",
    "            matrices[j][v] = matrices[j][v] + matrices[j - 1][u]\n",
    "        previous_time = t\n",
    "    # move time to previous_time + 1\n",
    "    for j in range(num_layer, 0, -1):\n",
    "        matrices[j] = matrices[j] * np.power(np.exp(-lam * 1), j)\n",
    "    \n",
    "    # esitmate the matrix by inner product\n",
    "    if use_projection:\n",
    "        matrices = [matrices[i] @ matrices[0].T for i in range(num_layer + 1)]\n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dad22d-fa33-410a-b499-f77bde3d1651",
   "metadata": {},
   "source": [
    "#### Matrix Updating Function for Batch Interaction Updating\n",
    "Given a temporal graph $G(t)$, the following two functions compute the corresponding temporal walk matrices at $t+1$ by updating the matrices incrementally, one batch of interactions at a time, if the following two conditions are satisfied\n",
    "- The timestamps of interactions in the previous batch are smaller than those in the current batch\n",
    "- Only using the interactions in current batch will not produce a temporal walk of length larger than 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7b8e24-16fd-4b08-90be-5bf59f55c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_matrix_by_batch_updating(src_node_ids, dst_node_ids, interact_times, num_layer, node_num, lam,\n",
    "                                      use_projection, dimension, batch_size, device):\n",
    "    \"\"\"\n",
    "    given a temporal graph G(t), generate the norm temporal walk matrices at t+1.\n",
    "    \"\"\"\n",
    "    if use_projection:\n",
    "        matrices = [torch.normal(0, 1 / math.sqrt(dimension), (node_num, dimension)).to(device)]\n",
    "        matrices = matrices + [torch.zeros(node_num, dimension).to(device) for i in range(num_layer)]\n",
    "    else:\n",
    "        matrices = [torch.eye(node_num).to(device)] + [torch.zeros((node_num, node_num)).to(device) for i in\n",
    "                                                       range(num_layer)]\n",
    "\n",
    "    degree = torch.zeros(node_num).to(device)\n",
    "    previous_time = 0\n",
    "    for l in range(0, len(src_node_ids), batch_size):\n",
    "        r = min(l + batch_size, len(src_node_ids))\n",
    "        batch_src_node_ids = src_node_ids[l:r]\n",
    "        batch_dst_node_ids = dst_node_ids[l:r]\n",
    "        batch_node_interact_times = interact_times[l:r]\n",
    "        next_time = batch_node_interact_times[-1]\n",
    "        # move current timestamp to next_time\n",
    "        degree = degree * np.exp(-lam * (next_time - previous_time))\n",
    "\n",
    "        # add interaction\n",
    "        concat_target_nodes = np.concatenate([batch_src_node_ids, batch_dst_node_ids])\n",
    "        concat_source_nodes = np.concatenate([batch_dst_node_ids, batch_src_node_ids])\n",
    "        link_weight = np.exp(-lam * (next_time - np.tile(batch_node_interact_times, 2)))\n",
    "        link_weight = torch.from_numpy(link_weight).to(device=device, dtype=torch.float32)\n",
    "        delta_degree = torch.zeros_like(degree)\n",
    "        delta_degree.scatter_add_(dim=0, src=link_weight, index=torch.from_numpy(concat_target_nodes).to(device))\n",
    "        link_weight = (link_weight / (degree[concat_target_nodes] + delta_degree[concat_target_nodes]))\n",
    "\n",
    "        for j in range(num_layer, 0, -1):\n",
    "            message = link_weight[:, None] * (-matrices[j][concat_target_nodes] + matrices[j - 1][concat_source_nodes])\n",
    "            matrices[j].scatter_add_(dim=0, src=message,\n",
    "                                     index=torch.from_numpy(concat_target_nodes)[:, None].to(device).\n",
    "                                     expand(-1, matrices[j].shape[1]))\n",
    "        degree = degree + delta_degree\n",
    "        previous_time = next_time\n",
    "\n",
    "    # esitmate the matrix by inner product\n",
    "    if use_projection:\n",
    "        matrices = [matrices[i] @ matrices[0].T for i in range(num_layer + 1)]\n",
    "    # move matrices to cpu\n",
    "    matrices = [matrices[i].cpu() for i in range(num_layer + 1)]\n",
    "    return matrices\n",
    "\n",
    "\n",
    "def get_sum_matrix_by_batch_updating(src_node_ids, dst_node_ids, interact_times, num_layer, node_num, lam,\n",
    "                                     use_projection, dimension, batch_size, device):\n",
    "    \"\"\"\n",
    "    given a temporal graph G(t), generate the sum temporal walk matrices at t+1.\n",
    "    \"\"\"\n",
    "    if use_projection:\n",
    "        matrices = [torch.normal(0, 1 / math.sqrt(dimension), (node_num, dimension)).to(device)]\n",
    "        matrices = matrices + [torch.zeros(node_num, dimension).to(device) for i in range(num_layer)]\n",
    "    else:\n",
    "        matrices = [torch.eye(node_num).to(device)] + [torch.zeros((node_num, node_num)).to(device) for i in\n",
    "                                                       range(num_layer)]\n",
    "\n",
    "    previous_time = 0\n",
    "    for l in range(0, len(src_node_ids), batch_size):\n",
    "        r = min(l + batch_size, len(src_node_ids))\n",
    "        batch_src_node_ids = src_node_ids[l:r]\n",
    "        batch_dst_node_ids = dst_node_ids[l:r]\n",
    "        batch_node_interact_times = interact_times[l:r]\n",
    "        next_time = batch_node_interact_times[-1]\n",
    "        # move current timestamp to next_time\n",
    "        for j in range(num_layer, 0, -1):\n",
    "            matrices[j] = matrices[j] * np.power(np.exp(-lam * (next_time - previous_time)), j)\n",
    "\n",
    "        concat_target_nodes = np.concatenate([batch_src_node_ids, batch_dst_node_ids])\n",
    "        concat_source_nodes = np.concatenate([batch_dst_node_ids, batch_src_node_ids])\n",
    "        link_weight = np.exp(-lam * (next_time - np.tile(batch_node_interact_times, 2)))\n",
    "        link_weight = torch.from_numpy(link_weight).to(device=device, dtype=torch.float32)\n",
    "        for j in range(num_layer, 0, -1):\n",
    "            matrices[j].scatter_add_(dim=0, src=matrices[j - 1][concat_source_nodes] * link_weight[:, None],\n",
    "                                     index=torch.from_numpy(concat_target_nodes)[:, None].to(device).\n",
    "                                     expand(-1, matrices[j].shape[1]))\n",
    "        previous_time = next_time\n",
    "    # move time to previous_time + 1\n",
    "    for j in range(num_layer, 0, -1):\n",
    "        matrices[j] = matrices[j] * np.power(np.exp(-lam * 1), j)\n",
    "\n",
    "    # esitmate the matrix by inner product\n",
    "    if use_projection:\n",
    "        matrices = [matrices[i] @ matrices[0].T for i in range(num_layer + 1)]\n",
    "    # move matrices to cpu\n",
    "    matrices = [matrices[i].cpu() for i in range(num_layer + 1)]\n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f64f31-1622-41ac-943e-a098071a784d",
   "metadata": {},
   "source": [
    "#### Unify All Things Together\n",
    "In this part, we shows that the imcremental updating mechanism can generate the same temporal walk matrices as the brute force method.\n",
    "\n",
    "We first show the correctness of the updating mechnaism for single interactoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff262c0-23e6-4a4a-8388-9977e76d26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set relevant hyperparameters\n",
    "node_num = 100\n",
    "edge_num = 500\n",
    "lam = 0.0001\n",
    "num_layer = 3\n",
    "dimension = 50\n",
    "# generate a random graph\n",
    "src_node_ids,dst_node_ids,node_interact_times = generate_graph(node_num=node_num,edge_num=edge_num)\n",
    "# get matrices by different methods\n",
    "sum_matrices_by_brute_force = get_matrix_by_brute_force(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,interact_times=node_interact_times,\n",
    "                                         matrix_type='sum',lam=lam,num_layer=num_layer,node_num=node_num)\n",
    "norm_matrices_by_brute_force = get_matrix_by_brute_force(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,interact_times=node_interact_times,\n",
    "                                         matrix_type='norm',lam=lam,num_layer=num_layer,node_num=node_num)\n",
    "sum_matrices_by_single_update = get_sum_matrix(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,interact_times=node_interact_times,lam=lam,\n",
    "                                               num_layer=num_layer,node_num=node_num,use_projection=False,dimension=0)\n",
    "norm_matrices_by_single_update = get_norm_matrix(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,interact_times=node_interact_times,lam=lam,\n",
    "                                               num_layer=num_layer,node_num=node_num,use_projection=False,dimension=0)\n",
    "\n",
    "for i in range(num_layer+1):\n",
    "    assert torch.allclose(sum_matrices_by_single_update[i],sum_matrices_by_brute_force[i],rtol=1e-5,atol=1e-5),\\\n",
    "        f\"{i}\\n{sum_matrices_by_brute_force[i]}\\n{sum_matrices_by_single_update[i]}\"\n",
    "    assert torch.allclose(norm_matrices_by_single_update[i],norm_matrices_by_brute_force[i],rtol=1e-5,atol=1e-5),\\\n",
    "    f\"{i}\\n{norm_matrices_by_brute_force[i]}\\n{norm_matrices_by_single_update[i]}\"\n",
    "\n",
    "# implicitly maintain the temporal walk matrices by random projections\n",
    "projected_sum_matrices_by_single_update = get_sum_matrix(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,interact_times=node_interact_times,lam=lam,\n",
    "                                               num_layer=num_layer,node_num=node_num,use_projection=True,dimension=dimension)\n",
    "projected_norm_matrices_by_single_update = get_norm_matrix(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,interact_times=node_interact_times,\n",
    "                                                           lam=lam,num_layer=num_layer,node_num=node_num,use_projection=True,dimension=dimension)\n",
    "\n",
    "def get_error_ratio(estimated_matrix,ground_truth_matrix):\n",
    "    \"\"\"\n",
    "    The the estimated temporal walk matrix A'_{u,v}^{(k)} is caculated by <h_u^{(k)},h_v^{(0)}> \n",
    "    in the above functions, where h_u^{(k)} is the projection of the A_u^{(k)}.\n",
    "    In this function, we compute $\\frac{|<h_u^{(k)},h_v^{(0)}>-<A_u^{(k)},A_v^{(0)}>|}{0.5*(||A_u^{(k)}||_2^2+||A_v^{(0)}||_2^2)}$, which\n",
    "    correspond $\\epsion$ in theorem 2 of the original paper\n",
    "    \"\"\"\n",
    "    delta_matrix = torch.abs(estimated_matrix-ground_truth_matrix)\n",
    "    epsilon = delta_matrix / (0.5*(torch.sum(ground_truth_matrix**2,dim=1)[:,None]+1))\n",
    "    return torch.mean(epsilon)\n",
    "    \n",
    "for i in range(num_layer+1):\n",
    "    ratio1 = get_error_ratio(projected_norm_matrices_by_single_update[i],norm_matrices_by_brute_force[i])\n",
    "    ratio2 = get_error_ratio(projected_sum_matrices_by_single_update[i],sum_matrices_by_brute_force[i])\n",
    "    assert ratio1 < 0.2, f\"norm{i}: {ratio1}\"\n",
    "    assert ratio2 < 0.2, f\"sum{i}: {ratio2}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ec38f4-68af-4f79-8799-e7f441fe55d8",
   "metadata": {},
   "source": [
    "We then show the correctness of the updating mechnaism for batch interactoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df0c411b-84c0-4dba-8aa2-e409461784c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set relevant hyperparameters\n",
    "node_num = 100\n",
    "edge_num = 500\n",
    "lam = 0.0001\n",
    "num_layer = 3\n",
    "dimension = 50\n",
    "batch_size = 10\n",
    "device = 'cuda:0'\n",
    "# generate a random graph\n",
    "src_node_ids,dst_node_ids,node_interact_times = generate_graph(node_num=node_num,edge_num=edge_num)\n",
    "# change the timestamps to satisfy the conditions of batch updating mechanism\n",
    "assert (edge_num // batch_size) * batch_size == edge_num\n",
    "node_interact_times = np.repeat(np.arange(1, edge_num//batch_size+1),batch_size)\n",
    "\n",
    "# get matrices by different methods\n",
    "sum_matrices_by_brute_force = get_matrix_by_brute_force(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,interact_times=node_interact_times,\n",
    "                                         matrix_type='sum',lam=lam,num_layer=num_layer,node_num=node_num)\n",
    "norm_matrices_by_brute_force = get_matrix_by_brute_force(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,interact_times=node_interact_times,\n",
    "                                         matrix_type='norm',lam=lam,num_layer=num_layer,node_num=node_num)    \n",
    "sum_matrices_by_batch_update = get_sum_matrix_by_batch_updating(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,\n",
    "                                                                interact_times=node_interact_times,lam=lam,num_layer=num_layer,\n",
    "                                                                node_num=node_num,use_projection=False,dimension=0,\n",
    "                                                               batch_size=batch_size,device=device)\n",
    "norm_matrices_by_batch_update = get_norm_matrix_by_batch_updating(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,\n",
    "                                                                   interact_times=node_interact_times,lam=lam,num_layer=num_layer,\n",
    "                                                                   node_num=node_num,use_projection=False,dimension=0,\n",
    "                                                                  batch_size=batch_size,device=device)\n",
    "\n",
    "for i in range(num_layer+1):\n",
    "    assert torch.allclose(sum_matrices_by_batch_update[i],sum_matrices_by_brute_force[i],rtol=1e-5,atol=1e-5),\\\n",
    "        f\"{i}\\n{sum_matrices_by_brute_force[i]}\\n{sum_matrices_by_batch_update[i]}\"\n",
    "    assert torch.allclose(norm_matrices_by_batch_update[i],norm_matrices_by_brute_force[i],rtol=1e-5,atol=1e-5),\\\n",
    "    f\"{i}\\n{norm_matrices_by_brute_force[i]}\\n{norm_matrices_by_batch_update[i]}\"\n",
    "\n",
    "# implicitly maintain the temporal walk matrices by random projections\n",
    "projected_sum_matrices_by_batch_update = get_sum_matrix_by_batch_updating(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,\n",
    "                                                                interact_times=node_interact_times,lam=lam,num_layer=num_layer,\n",
    "                                                                node_num=node_num,use_projection=True,dimension=dimension,\n",
    "                                                               batch_size=batch_size,device=device)\n",
    "projected_norm_matrices_by_batch_update = get_norm_matrix_by_batch_updating(src_node_ids=src_node_ids,dst_node_ids=dst_node_ids,\n",
    "                                                                   interact_times=node_interact_times,lam=lam,num_layer=num_layer,\n",
    "                                                                   node_num=node_num,use_projection=True,dimension=dimension,\n",
    "                                                                  batch_size=batch_size,device=device)\n",
    "    \n",
    "for i in range(num_layer+1):\n",
    "    ratio1 = get_error_ratio(projected_norm_matrices_by_batch_update[i],norm_matrices_by_brute_force[i])\n",
    "    ratio2 = get_error_ratio(projected_sum_matrices_by_batch_update[i],sum_matrices_by_brute_force[i])\n",
    "    assert ratio1 < 0.2, f\"norm{i}: {ratio1}\"\n",
    "    assert ratio2 < 0.2, f\"sum{i}: {ratio2}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
